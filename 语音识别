GMM-HMM模型：
  HMM 中的隐状态对应的是语音的音素状态
  HMM 中的状态转移概率  状态对应的是音素， 音素对应的是特征， 所以求状态转移概率就是训练的过程， 使特征转移到另一个特征的概率最大；
  HMM 中的观察概率      通过GMM来求特征的似然概率；
  
  http://pelhans.com/2018/01/13/deepspeech-oldasr/
  https://blog.csdn.net/qq_37385726/article/details/89217990#HMM%E7%9A%84%E7%AC%AC%E4%BA%8C%E7%B1%BB%E9%97%AE%E9%A2%98%E4%BD%BF%E7%94%A8%E7%BB%B4%E7%89%B9%E6%AF%94%E7%AE%97%E6%B3%95%E7%9A%84%E5%BA%94%E7%94%A8
  
  https://blog.csdn.net/Joyliness/article/details/79603950





维特比算法
 greedy 的方法虽然能求出每一帧每一步的观察概率最大值， 但是这个最大值只是观察概率的， 没有考虑到观察状态所对应的隐层状态之间的转移概率，
 所以就是假使两个隐层状态之间完全没有关系， 转移概率为0， greedy的方法也是就直接粗暴的这样做了。
 
 那么现在我在考虑ce loss的训练的方式也是要求帧对应的预测值与正确值达到最大， 而没有考虑到预测值之间的转移概率，  这个转移概率可以通过拼帧的想法来改善，
 使得帧与帧之间有联系。
 
 也就是说不仅在解码过程中要考虑到帧与帧之间的转移关系， 在训练过程中也要考虑到帧与帧之间的转移关系， 拼帧是一种想法， 还有其他的策略没？


维特比算法用来求
 给定观察序列之后和HMM模型参数之后， 求最有可能的隐含状态序列， 可以用维特比算法来解决这个问题， 所以其实这是一个解码问题， 这个问题也可以通过greed search， beam search来解决。
 
 这个解码还可以通过wfst来解决。
 

